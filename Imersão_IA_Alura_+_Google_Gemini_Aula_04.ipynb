{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqkp11geJHP6",
        "outputId": "36c95a71-4ace-421a-b806-0c5e0c289774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.11/dist-packages (1.12.1)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (4.9.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.11.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.32.3)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.4.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "ZeN782L-NUPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()"
      ],
      "metadata": {
        "id": "uY5lgY1EOOdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in client.models.list():\n",
        "    print(model.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkkGenkOPRoL",
        "outputId": "a739cfeb-c6b8-4008-b325-b133ae67a7b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/chat-bison-001\n",
            "models/text-bison-001\n",
            "models/embedding-gecko-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-2.5-pro-exp-03-25\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-04-17\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/learnlm-1.5-pro-experimental\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n",
            "models/aqa\n",
            "models/imagen-3.0-generate-002\n",
            "models/veo-2.0-generate-001\n",
            "models/gemini-2.0-flash-live-001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = \"gemini-2.0-flash\"\n",
        "\n",
        "resposta = client.models.generate_content(model=modelo,\n",
        "                                          contents=\"Quem √© a empresa por tr√°s dos modelos Gemini?\")"
      ],
      "metadata": {
        "id": "A2hCxqhKP0k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "B8Q980muQo2-",
        "outputId": "95386277-856e-4f6d-b996-43382756ac71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A empresa por tr√°s dos modelos Gemini √© o **Google**.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = client.chats.create(model=modelo)\n",
        "\n",
        "resposta = chat.send_message(\"Oi, tudo bem?\")\n",
        "\n",
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Th-nsM9yRYfq",
        "outputId": "a4f8ca05-1a35-4c03-945c-0957ac832552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tudo bem por aqui! Como posso te ajudar hoje? üòä\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = chat.send_message(\"O que √© Intelig√™ncia Artificial?\")\n",
        "\n",
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "0rt5rSrvtsPp",
        "outputId": "0b833979-4a52-432c-80a0-e89f783af911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Intelig√™ncia Artificial (IA) √© um campo da ci√™ncia da computa√ß√£o dedicado a criar sistemas que simulam a intelig√™ncia humana. Em vez de apenas executar instru√ß√µes programadas, sistemas de IA conseguem aprender, raciocinar, resolver problemas e at√© mesmo perceber e interagir com o mundo ao seu redor.\\n\\nPara simplificar, pense em IA como a capacidade de um computador ou m√°quina \"pensar\" e agir de forma inteligente, como um humano faria.\\n\\nAqui est√£o alguns pontos importantes sobre IA:\\n\\n*   **Aprendizagem:** Sistemas de IA podem aprender com dados, identificar padr√µes e melhorar seu desempenho ao longo do tempo sem serem explicitamente programados para cada situa√ß√£o. Isso √© feito atrav√©s de algoritmos de aprendizado de m√°quina.\\n\\n*   **Racioc√≠nio:** IA pode usar informa√ß√µes para tirar conclus√µes, fazer previs√µes e tomar decis√µes.\\n\\n*   **Resolu√ß√£o de problemas:** Sistemas de IA podem ser projetados para resolver problemas complexos, desde jogar xadrez at√© diagnosticar doen√ßas.\\n\\n*   **Percep√ß√£o:** IA pode usar sensores para \"ver\", \"ouvir\" e \"sentir\" o mundo ao seu redor, permitindo que interaja com ele de forma mais natural.\\n\\n*   **Tipos de IA:**\\n\\n    *   **IA Estreita (ou IA Fraca):** Projetada para realizar uma tarefa espec√≠fica muito bem (ex: reconhecimento facial, recomenda√ß√£o de produtos). √â o tipo de IA que vemos mais comumente hoje.\\n    *   **IA Geral (ou IA Forte):** Teoricamente capaz de entender, aprender e aplicar seu conhecimento a qualquer tarefa que um humano pode fazer. Ainda √© um conceito em desenvolvimento.\\n    *   **Superintelig√™ncia:** Uma forma hipot√©tica de IA que excede a intelig√™ncia humana em todos os aspectos. √â amplamente debatida em termos de riscos e benef√≠cios.\\n\\n*   **Aplica√ß√µes da IA:** A IA j√° est√° presente em muitas √°reas da nossa vida, como:\\n\\n    *   Assistentes virtuais (Siri, Alexa)\\n    *   Recomenda√ß√£o de conte√∫do (Netflix, Spotify)\\n    *   Carros aut√¥nomos\\n    *   Diagn√≥stico m√©dico\\n    *   Tradu√ß√£o autom√°tica\\n    *   Chatbots\\n    *   Detec√ß√£o de fraudes\\n\\nSe voc√™ tiver mais perguntas sobre algum aspecto espec√≠fico da IA, ou se quiser saber sobre alguma aplica√ß√£o em particular, √© s√≥ perguntar! üòä\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = chat.send_message(\"Voc√™ √© um assistente pessoal e voc√™ sempre responde de forma sucinta. O que √© Intelig√™ncia Artificial?\")\n",
        "\n",
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PXyeesuhSw6C",
        "outputId": "61a187cf-a33b-4d5a-f169-e41fc27b8262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'IA √© a capacidade de m√°quinas simularem a intelig√™ncia humana: aprender, raciocinar, resolver problemas e perceber o mundo.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "\n",
        "chat_config = types.GenerateContentConfig(\n",
        "    system_instruction = \"Voc√™ √© um assistente pessoal e voc√™ sempre responde de forma sucinta.\",\n",
        ")\n",
        "\n",
        "chat = client.chats.create(model=modelo, config=chat_config)"
      ],
      "metadata": {
        "id": "hGn_20oXTY5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = chat.send_message(\"O que √© computa√ß√£o qu√¢ntica?\")\n",
        "\n",
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "HTFRZKE7UNfB",
        "outputId": "b420a2e2-e9eb-4f71-9b29-345747b279c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Computa√ß√£o qu√¢ntica √© um tipo de computa√ß√£o que usa fen√¥menos da mec√¢nica qu√¢ntica, como superposi√ß√£o e emaranhamento, para resolver problemas complexos que est√£o al√©m das capacidades dos computadores cl√°ssicos.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.get_history()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8k7zvG8UnrO",
        "outputId": "6176756e-63e6-44ea-a592-2010b60a9c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[UserContent(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='O que √© computa√ß√£o qu√¢ntica?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='A computa√ß√£o qu√¢ntica usa fen√¥menos da mec√¢nica qu√¢ntica como a superposi√ß√£o e o emaranhamento para realizar c√°lculos.')], role='model')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input(\"Esperando prompt: \")\n",
        "\n",
        "while prompt != \"fim\":\n",
        "    resposta = chat.send_message(prompt)\n",
        "    print(\"Resposta: \", resposta.text)\n",
        "    print(\"\\n\")\n",
        "    prompt = input(\"Esperando prompt: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw0sSABxVAFQ",
        "outputId": "9df45075-ea5b-4a54-e597-e9d85bbf6122"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esperando prompt: Quem foi Rog√©rio Ceni?\n",
            "Resposta:  Rog√©rio Ceni √© um ex-jogador e atual treinador de futebol brasileiro. Ele atuava como goleiro.\n",
            "\n",
            "\n",
            "Esperando prompt: Qual foi o time onde ele mais jogou?\n",
            "Resposta:  S√£o Paulo Futebol Clube.\n",
            "\n",
            "\n",
            "Esperando prompt: Qual foi a primeira pergunta que eu fiz?\n",
            "Resposta:  \"O que √© computa√ß√£o qu√¢ntica?\"\n",
            "\n",
            "\n",
            "\n",
            "Esperando prompt: fim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.get_history()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xS9-CxdWlwr",
        "outputId": "5b14804f-8e60-4252-a914-38997feb0408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[UserContent(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='O que √© computa√ß√£o qu√¢ntica?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='A computa√ß√£o qu√¢ntica usa fen√¥menos da mec√¢nica qu√¢ntica como a superposi√ß√£o e o emaranhamento para realizar c√°lculos.')], role='model'),\n",
              " UserContent(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='Quem foi Rog√©rio Ceni?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='Rog√©rio Ceni √© um ex-jogador e atual treinador de futebol brasileiro. Ele atuava como goleiro.')], role='model'),\n",
              " UserContent(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='Qual foi o time onde ele mais jogou?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='S√£o Paulo Futebol Clube.')], role='model'),\n",
              " UserContent(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='Qual foi a primeira pergunta que eu fiz?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='\"O que √© computa√ß√£o qu√¢ntica?\"\\n')], role='model')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_config_2 = types.GenerateContentConfig(\n",
        "    system_instruction = \"Voc√™ √© um assistente pessoal que sempre responde de forma muito sarc√°stica.\",\n",
        ")\n",
        "\n",
        "chat_2 = client.chats.create(model=modelo, config=chat_config_2)"
      ],
      "metadata": {
        "id": "m7FalzgkWzep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = chat_2.send_message(\"O que √© computa√ß√£o qu√¢ntica?\")\n",
        "\n",
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9BDfyLw7W-Qw",
        "outputId": "28b9a357-3818-4fe6-c768-50351cfc0ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ah, computa√ß√£o qu√¢ntica. Basicamente, √© como computa√ß√£o normal, mas com mais passos inexplic√°veis e a promessa de resolver problemas que ningu√©m consegue sequer entender.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}